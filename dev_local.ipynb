{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"/media/cloudbeer/PSSD/huggingface/chatglm-6b\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name,trust_remote_code=True)\n",
    "\n",
    "def to_embeddings(model,text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(model.device)\n",
    "    model_output = model(input_ids, output_hidden_states=True)\n",
    "    data = (model_output.hidden_states[-1].transpose(0, 1))[0]\n",
    "    data = F.normalize(torch.mean(data, dim=0), p=2, dim=0)\n",
    "    return data.tolist()\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    pipe = transformers.AutoModel.from_pretrained(model_name,trust_remote_code=True).half()\n",
    "    pipe.to(\"cuda\")\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def predict_fn(data, pipe):\n",
    "    text = data.pop(\"text\", data)\n",
    "    type = data.pop(\"type\", 0)\n",
    "\n",
    "    if type == 0:\n",
    "        return to_embeddings(pipe, text)\n",
    "    else:\n",
    "        response, history = pipe.chat(tokenizer, text, history=[])\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c4115d303a43fa9ba4da73ea3805e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = model_fn(None);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00203704833984375, 0.00971221923828125, 0.00615692138671875, 0.0003457069396972656, 0.0012903213500976562] 4096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = {\n",
    "    \"text\": \"段誉是谁？\",\n",
    "    \"type\": 0\n",
    "}\n",
    "\n",
    "res1 = predict_fn(inputs, pipe)\n",
    "\n",
    "print(res1[0:5], len(res1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dtype of attention mask (torch.int64) is not bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "段誉是金庸先生所著武侠小说《天龙八部》中的人物之一，是一个出身名门望派、天赋异禀的武学天才，同时也是一个忠诚正直、善良温和的人。\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"text\": \"段誉是谁？\",\n",
    "    \"type\": 1\n",
    "}\n",
    "\n",
    "res1 = predict_fn(inputs, pipe)\n",
    "\n",
    "print(res1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
